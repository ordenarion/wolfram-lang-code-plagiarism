{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataLoading\n",
    "import wolframPreprocessing\n",
    "import myWMEncoder\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from unixcoder import UniXcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dataLoading.DataLoaderExporter()\n",
    "preprocessor = wolframPreprocessing.WolframPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.make_json_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load_json_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"transformed_code\"] = data[\"code\"].apply(lambda x: preprocessor.preprocessing_composition_naive(x, tokenize=True))\n",
    "data.drop(data[data[\"transformed_code\"].apply(lambda x: len(x) == 0)].index, inplace=True)\n",
    "data[\"tr_code_non_tokenized\"] = data[\"code\"].apply(lambda x: preprocessor.preprocessing_composition_naive(x, tokenize=False))\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"task\"] == data[\"task\"].unique()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = myWMEncoder.CustomEncoder(50)\n",
    "encoder.fit(data[\"transformed_code\"].values)\n",
    "encoder_size = encoder.vec_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, data, encoder, window_size=5):\n",
    "        self.data = data\n",
    "        self.encoder = encoder\n",
    "        self.encoder.fit(data)\n",
    "        self.window_size = window_size\n",
    "        self.windows = None\n",
    "        self.labels = np.array([])\n",
    "        self.start = True\n",
    "\n",
    "        for string in self.data:\n",
    "            tmp = sliding_window_view(string, window_size + 1)\n",
    "            for win in tmp:\n",
    "                encoded_win = self.encoder.transform(win)\n",
    "                x = np.array([encoded_win[:-1]])\n",
    "                label = np.array([np.argmax(encoded_win[-1][:-2])])\n",
    "                if self.start:\n",
    "                    self.windows = x\n",
    "                    self.start = False\n",
    "                else:\n",
    "                    self.windows = np.concatenate((self.windows, x))\n",
    "                self.labels = np.concatenate((self.labels, label))\n",
    "\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "        self.windows = torch.FloatTensor(self.windows)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.windows[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDatasetOpt(Dataset):\n",
    "    def __init__(self, data, encoder, window_size=5):\n",
    "        self.data = data\n",
    "        self.encoder = encoder\n",
    "        self.encoder.fit(data)\n",
    "        self.window_size = window_size\n",
    "        self.windows = None\n",
    "        self.labels = np.array([])\n",
    "        self.start = True\n",
    "\n",
    "        for code in self.data:\n",
    "            transformed_code = self.encoder.transform(code)\n",
    "            sliding_windows = sliding_window_view(transformed_code, (self.window_size + 1, self.encoder.vec_size)).reshape(-1, self.window_size + 1, self.encoder.vec_size)\n",
    "            x = sliding_windows[:, :-1]\n",
    "            labels = np.argmax(sliding_windows[:, -1,: -2], axis=1)\n",
    "            if self.start:\n",
    "                self.windows = x\n",
    "                self.labels = labels\n",
    "                self.start = False\n",
    "            else:\n",
    "                self.windows = np.concatenate((self.windows, x))\n",
    "                self.labels = np.concatenate((self.labels, labels))\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "        self.windows = torch.FloatTensor(self.windows)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.windows[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = myWMEncoder.CustomEncoder(50)\n",
    "new_dataset = WindowDatasetOpt(data[\"transformed_code\"].values, enc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(new_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMWindow(nn.Module):\n",
    "    def __init__(self, hidden_size, vec_size):\n",
    "        super(LSTMWindow, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.vec_size = vec_size\n",
    "        self.n_classes = vec_size - 2\n",
    "        self.lstm = nn.LSTM(self.vec_size,\n",
    "                        self.hidden_size,\n",
    "                        num_layers=1,\n",
    "                        batch_first=True,\n",
    "                        bidirectional=False\n",
    "                        )\n",
    "        self.lin_layer = nn.Linear(self.hidden_size, self.n_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        h_0 = torch.zeros(1, inputs.size(0), self.hidden_size)\n",
    "        c_0 = torch.zeros(1, inputs.size(0), self.hidden_size)\n",
    "        output_features, (h_out, _) = self.lstm(inputs, (h_0, c_0))  \n",
    "        self.h_out = h_out.view(-1, self.hidden_size)  \n",
    "        return self.lin_layer(self.h_out)\n",
    "    \n",
    "    def emb(self, inputs):\n",
    "        self.forward(inputs)\n",
    "        return self.h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = LSTMWindow(300, new_dataset.encoder.vec_size)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::   2%|▏         | 1/50 [00:04<03:55,  4.80s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100], mean_epoch_loss: 2.1130449447265036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::   4%|▍         | 2/50 [00:09<03:49,  4.78s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/100], mean_epoch_loss: 1.2032436517568734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::   6%|▌         | 3/50 [00:14<03:43,  4.75s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/100], mean_epoch_loss: 0.9379906880855561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::   8%|▊         | 4/50 [00:18<03:35,  4.69s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/100], mean_epoch_loss: 0.7723847158138568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  10%|█         | 5/50 [00:23<03:31,  4.70s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/100], mean_epoch_loss: 0.6522561644590817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  12%|█▏        | 6/50 [00:28<03:26,  4.69s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/100], mean_epoch_loss: 0.5658410020516469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  14%|█▍        | 7/50 [00:32<03:21,  4.69s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/100], mean_epoch_loss: 0.49874658465385435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  16%|█▌        | 8/50 [00:37<03:15,  4.66s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/100], mean_epoch_loss: 0.45757623631220595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  18%|█▊        | 9/50 [00:42<03:11,  4.66s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/100], mean_epoch_loss: 0.4083310693273178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  20%|██        | 10/50 [00:47<03:08,  4.71s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/100], mean_epoch_loss: 0.36795809887922726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  22%|██▏       | 11/50 [00:51<03:03,  4.70s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11/100], mean_epoch_loss: 0.33442729757382317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  24%|██▍       | 12/50 [00:56<02:58,  4.69s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12/100], mean_epoch_loss: 0.3265821451177964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  26%|██▌       | 13/50 [01:00<02:52,  4.66s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/100], mean_epoch_loss: 0.3164060534651463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  28%|██▊       | 14/50 [01:05<02:47,  4.64s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14/100], mean_epoch_loss: 0.29723392738745763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  30%|███       | 15/50 [01:10<02:42,  4.64s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/100], mean_epoch_loss: 0.2899903727036256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  32%|███▏      | 16/50 [01:14<02:37,  4.63s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/100], mean_epoch_loss: 0.28301978491819824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  34%|███▍      | 17/50 [01:19<02:32,  4.64s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17/100], mean_epoch_loss: 0.2858679527044296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  36%|███▌      | 18/50 [01:24<02:28,  4.63s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[18/100], mean_epoch_loss: 0.25313861570679225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  38%|███▊      | 19/50 [01:28<02:23,  4.63s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/100], mean_epoch_loss: 0.2494994190793771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  40%|████      | 20/50 [01:33<02:18,  4.62s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/100], mean_epoch_loss: 0.23997730649434604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  42%|████▏     | 21/50 [01:38<02:14,  4.65s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21/100], mean_epoch_loss: 0.24770494942481702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  44%|████▍     | 22/50 [01:42<02:11,  4.71s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/100], mean_epoch_loss: 0.25291938554782134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  46%|████▌     | 23/50 [01:48<02:13,  4.93s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[23/100], mean_epoch_loss: 0.243939335082586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  48%|████▊     | 24/50 [01:53<02:11,  5.07s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[24/100], mean_epoch_loss: 0.21624074496901952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  50%|█████     | 25/50 [01:58<02:03,  4.95s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/100], mean_epoch_loss: 0.21777233343857985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  52%|█████▏    | 26/50 [02:03<01:56,  4.87s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26/100], mean_epoch_loss: 0.22610657403102288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  54%|█████▍    | 27/50 [02:07<01:50,  4.80s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[27/100], mean_epoch_loss: 0.2242743625319921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  56%|█████▌    | 28/50 [02:12<01:44,  4.77s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28/100], mean_epoch_loss: 0.25714075525219626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  58%|█████▊    | 29/50 [02:17<01:39,  4.76s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[29/100], mean_epoch_loss: 0.24892475948883938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  60%|██████    | 30/50 [02:21<01:34,  4.73s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30/100], mean_epoch_loss: 0.21459933342841955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  62%|██████▏   | 31/50 [02:26<01:29,  4.72s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31/100], mean_epoch_loss: 0.19103860532435088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  64%|██████▍   | 32/50 [02:31<01:24,  4.70s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[32/100], mean_epoch_loss: 0.18347709686137162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  66%|██████▌   | 33/50 [02:35<01:19,  4.68s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[33/100], mean_epoch_loss: 0.17535006540325973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  68%|██████▊   | 34/50 [02:40<01:14,  4.67s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/100], mean_epoch_loss: 0.1762904783624869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  70%|███████   | 35/50 [02:45<01:10,  4.68s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[35/100], mean_epoch_loss: 0.19471746511757373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  72%|███████▏  | 36/50 [02:50<01:06,  4.74s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[36/100], mean_epoch_loss: 0.23060439807864336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  74%|███████▍  | 37/50 [02:55<01:02,  4.83s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/100], mean_epoch_loss: 0.23678834818876707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  76%|███████▌  | 38/50 [02:59<00:57,  4.77s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[38/100], mean_epoch_loss: 0.23850450911200963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  78%|███████▊  | 39/50 [03:04<00:52,  4.73s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[39/100], mean_epoch_loss: 0.2283591104241518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  80%|████████  | 40/50 [03:08<00:46,  4.68s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/100], mean_epoch_loss: 0.19762776418374134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  82%|████████▏ | 41/50 [03:13<00:41,  4.66s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[41/100], mean_epoch_loss: 0.16722210069115345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  84%|████████▍ | 42/50 [03:18<00:37,  4.64s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[42/100], mean_epoch_loss: 0.1515310064645914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  86%|████████▌ | 43/50 [03:22<00:32,  4.63s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[43/100], mean_epoch_loss: 0.1441304641503554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  88%|████████▊ | 44/50 [03:27<00:27,  4.65s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[44/100], mean_epoch_loss: 0.14867161154173889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  90%|█████████ | 45/50 [03:32<00:23,  4.67s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[45/100], mean_epoch_loss: 0.15442519210278988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  92%|█████████▏| 46/50 [03:36<00:18,  4.64s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[46/100], mean_epoch_loss: 0.184585843785451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  94%|█████████▍| 47/50 [03:41<00:13,  4.65s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[47/100], mean_epoch_loss: 0.23394611691053097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  96%|█████████▌| 48/50 [03:45<00:09,  4.65s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[48/100], mean_epoch_loss: 0.24834877635423955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning::  98%|█████████▊| 49/50 [03:50<00:04,  4.62s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49/100], mean_epoch_loss: 0.21012466879991384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning:: 100%|██████████| 50/50 [03:55<00:00,  4.71s/carrots]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[50/100], mean_epoch_loss: 0.16424053297019922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in trange(50, desc=\"Learning:\", unit=\"carrots\"):\n",
    "    i = 1\n",
    "    mean_sum = 0\n",
    "    for id, (texts, targets) in enumerate(trainloader):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(texts)\n",
    "        loss = criterion(pred, targets)\n",
    "        mean_sum += loss.item()\n",
    "        i += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch[{epoch + 1}/100], mean_epoch_loss: {mean_sum/i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_need = new_dataset.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = [model.emb(torch.FloatTensor(np.array([enc_need.transform(tokens)])))[0].tolist() for tokens in data[\"transformed_code\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Levenshtein import ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_unix = UniXcoder(\"microsoft/unixcoder-base\")\n",
    "model_unix.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_embs, unixcoder_embs = {}, {}\n",
    "for name, code in enumerate(data[['name', 'task']].values):\n",
    "    tokens_ids = model.tokenize([code],max_length=512,mode=\"<encoder-only>\")\n",
    "    source_ids = torch.tensor(tokens_ids).to(device)\n",
    "    _, unix = model(source_ids)\n",
    "\n",
    "    lstm = model.emb([code])\n",
    "    lstm_embs[name] = lstm\n",
    "    unixcoder_embs[name] = unix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unix_embs(ind_pairs):\n",
    "    unix_values = []\n",
    "    for pair in ind_pairs:\n",
    "        sim_unix = torch.einsum(\"ac,bc->ab\",\n",
    "                                unixcoder_embs[pair[0]],\n",
    "                                unixcoder_embs[pair[1]])[0][0].item()\n",
    "        unix_values.append(sim_unix)\n",
    "    return unix_values\n",
    "\n",
    "def compute_lstm_embs(ind_pairs):\n",
    "    lstm_values = []\n",
    "    for pair in ind_pairs:\n",
    "        sim_lstm = cosine_similarity(lstm_embs[pair[0]], lstm_embs[pair[1]])[0][0]\n",
    "        lstm_values.append(sim_lstm)\n",
    "    return lstm_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_plags_alg1(clust, vertecies, models_weights, threshold):\n",
    "    total_info = []\n",
    "    for v0_ind in range(len(vertecies)):\n",
    "        for v1_ind in range(len(vertecies)):\n",
    "            if v0_ind < v1_ind:\n",
    "                v0, v1 = vertecies[[v0_ind, v1_ind]]\n",
    "                works_v0 = clust[clust[\"name\"] == v0][[\"file\", \"index\"]].values\n",
    "                works_v1 = clust[clust[\"name\"] == v1][[\"file\", \"index\"]].values\n",
    "                plags = []\n",
    "                for v0_file, v0_edge in works_v0:\n",
    "                    s0 = clust[clust[\"index\"] == v0_edge][\"tr_code_non_tokenized\"].values[0]\n",
    "                    for v1_file, v1_edge in works_v1:\n",
    "                        s1 = clust[clust[\"index\"] == v1_edge][\"tr_code_non_tokenized\"].values[0]\n",
    "                        sim_leven = Levenshtein.ratio(s0, s1)\n",
    "                        sim_unix = torch.einsum(\"ac,bc->ab\",unixcoder_embs[v0_edge],unixcoder_embs[v1_edge])[0][0].item()\n",
    "                        sim_lstm = cosine_similarity(lstm_embs[v0_edge], lstm_embs[v1_edge])[0][0]\n",
    "                        total_sim = models_weights @ [sim_leven, sim_lstm, sim_unix]\n",
    "                        if total_sim > threshold:\n",
    "                            plags.append([v0_file, v1_file, (sim_leven, sim_lstm, sim_unix, total_sim)])\n",
    "                if len(plags) > 0:\n",
    "                    total_info.append([v0, v1, plags, len(plags),\"label\", \"label\"])\n",
    "    return total_info    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_plags_alg2(clust, vertecies, models_weights, threshold_lvn_upper, threshold_lvn_lower, threshold_nn):\n",
    "    total_info = []\n",
    "    for v0_ind in range(len(vertecies)):\n",
    "        for v1_ind in range(len(vertecies)):\n",
    "            if v0_ind < v1_ind:\n",
    "                v0, v1 = vertecies[[v0_ind, v1_ind]]\n",
    "                works_v0 = clust[clust[\"name\"] == v0][[\"file\", \"index\"]].values\n",
    "                works_v1 = clust[clust[\"name\"] == v1][[\"file\", \"index\"]].values\n",
    "                plags = []\n",
    "                for v0_file, v0_edge in works_v0:\n",
    "                    s0 = clust[clust[\"index\"] == v0_edge][\"tr_code_non_tokenized\"].values[0]\n",
    "                    for v1_file, v1_edge in works_v1:\n",
    "                        s1 = clust[clust[\"index\"] == v1_edge][\"tr_code_non_tokenized\"].values[0]\n",
    "                        sim_leven = Levenshtein.ratio(s0, s1)\n",
    "                        sim_unix = torch.einsum(\"ac,bc->ab\",unixcoder_embs[v0_edge],unixcoder_embs[v1_edge])[0][0].item()\n",
    "                        sim_lstm = cosine_similarity(lstm_embs[v0_edge], lstm_embs[v1_edge])[0][0]\n",
    "\n",
    "                        if sim_leven >= threshold_lvn_upper:\n",
    "                            plags.append([v0_file, v1_file, (sim_leven, 0, 0, sim_leven)])\n",
    "                        elif threshold_lvn_lower <= sim_leven < threshold_lvn_upper:\n",
    "                            nn_sim = models_weights @ [sim_lstm, sim_unix]\n",
    "                            if nn_sim >= threshold_nn:\n",
    "                                plags.append([v0_file, v1_file, (sim_leven, 0, sim_unix, 0)])\n",
    "\n",
    "                if len(plags) > 0:\n",
    "                    total_info.append([v0, v1, plags, len(plags),\"label\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
